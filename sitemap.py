import os
import glob
from datetime import datetime
from urllib.parse import quote

def generate_sitemap():
    """sitemap.xml íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    base_url = "https://hyunwoo0815.github.io/bus2/"
    
    # XML í—¤ë”
    sitemap_content = '''<?xml version="1.0" encoding="UTF-8"?>
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">'''
    
    # outputs í´ë”ì˜ ëª¨ë“  HTML íŒŒì¼ ì°¾ê¸°
    html_files = glob.glob('outputs/*.html')
    
    # ê° HTML íŒŒì¼ì— ëŒ€í•œ URL ì¶”ê°€
    for html_file in sorted(html_files):
        filename = os.path.basename(html_file)
        
        # index.htmlì€ ì œì™¸ (í•„ìš”ì— ë”°ë¼ ìˆ˜ì • ê°€ëŠ¥)
        if filename == 'index.html':
            continue
            
        # URL ì¸ì½”ë”© (í•œê¸€ íŒŒì¼ëª… ì²˜ë¦¬)
        encoded_filename = quote(filename, safe='-._~')
        url = base_url + encoded_filename
        lastmod = datetime.now().strftime('%Y-%m-%d')
        
        sitemap_content += f'''
    <url>
        <loc>{url}</loc>
        <lastmod>{lastmod}</lastmod>
        <changefreq>daily</changefreq>
        <priority>0.8</priority>
    </url>'''
    
    # XML í‘¸í„°
    sitemap_content += '''
</urlset>'''
    
    # sitemap.xml íŒŒì¼ ì €ì¥
    os.makedirs('outputs', exist_ok=True)
    with open('outputs/sitemap.xml', 'w', encoding='utf-8') as f:
        f.write(sitemap_content)
    
    print(f"âœ… Sitemap ìƒì„± ì™„ë£Œ: {len(html_files)}ê°œ í˜ì´ì§€")

def generate_rss():
    """rss.xml íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    base_url = "https://hyunwoo0815.github.io/bus2/"
    
    # í˜„ì¬ ì‹œê°„
    build_date = datetime.now().strftime('%a, %d %b %Y %H:%M:%S GMT')
    
    # RSS í—¤ë”
    rss_content = f'''<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>ì „êµ­ ì‹œì™¸ë²„ìŠ¤ ì‹œê°„í‘œ</title>
        <description>ì „êµ­ ì‹œì™¸ë²„ìŠ¤ ë…¸ì„ ë³„ ì‹œê°„í‘œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤</description>
        <link>{base_url}</link>
        <atom:link href="{base_url}rss.xml" rel="self" type="application/rss+xml"/>
        <language>ko-kr</language>
        <lastBuildDate>{build_date}</lastBuildDate>
        <pubDate>{build_date}</pubDate>
        <ttl>1440</ttl>'''
    
    # outputs í´ë”ì˜ HTML íŒŒì¼ë“¤ ì°¾ê¸°
    html_files = glob.glob('outputs/*.html')
    
    # ìµœê·¼ íŒŒì¼ë“¤ì„ RSS ì•„ì´í…œìœ¼ë¡œ ì¶”ê°€ (ìµœëŒ€ 20ê°œ)
    recent_files = sorted(html_files, key=os.path.getmtime, reverse=True)[:20]
    
    for html_file in recent_files:
        filename = os.path.basename(html_file)
        
        # index.htmlì€ ì œì™¸
        if filename == 'index.html':
            continue
            
        # íŒŒì¼ëª…ì—ì„œ ë…¸ì„  ì •ë³´ ì¶”ì¶œ
        route_info = filename.replace('-ì‹œì™¸ë²„ìŠ¤-ì‹œê°„í‘œ.html', '').replace('-', ' â†’ ')
        
        # URL ì¸ì½”ë”©
        encoded_filename = quote(filename, safe='-._~')
        url = base_url + encoded_filename
        
        # íŒŒì¼ ìˆ˜ì • ì‹œê°„
        mtime = os.path.getmtime(html_file)
        pub_date = datetime.fromtimestamp(mtime).strftime('%a, %d %b %Y %H:%M:%S GMT')
        
        rss_content += f'''
        <item>
            <title>{route_info} ì‹œì™¸ë²„ìŠ¤ ì‹œê°„í‘œ</title>
            <description>{route_info} ë…¸ì„ ì˜ ì‹œì™¸ë²„ìŠ¤ ì‹œê°„í‘œ ì •ë³´ì…ë‹ˆë‹¤.</description>
            <link>{url}</link>
            <guid>{url}</guid>
            <pubDate>{pub_date}</pubDate>
        </item>'''
    
    # RSS í‘¸í„°
    rss_content += '''
    </channel>
</rss>'''
    
    # rss.xml íŒŒì¼ ì €ì¥
    with open('outputs/rss.xml', 'w', encoding='utf-8') as f:
        f.write(rss_content)
    
    print(f"âœ… RSS ìƒì„± ì™„ë£Œ: {len(recent_files)}ê°œ í•­ëª©")

def generate_robots_txt():
    """robots.txt íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    base_url = "https://hyunwoo0815.github.io/bus2/"
    
    robots_content = f'''User-agent: *
Allow: /

# Sitemap
Sitemap: {base_url}sitemap.xml

# í¬ë¡¤ë§ ì§€ì—° (1ì´ˆ)
Crawl-delay: 1'''
    
    with open('outputs/robots.txt', 'w', encoding='utf-8') as f:
        f.write(robots_content)
    
    print("âœ… robots.txt ìƒì„± ì™„ë£Œ")

if __name__ == "__main__":
    print("ğŸš€ SEO íŒŒì¼ ìƒì„± ì‹œì‘...")
    
    # outputs í´ë”ê°€ ìˆëŠ”ì§€ í™•ì¸
    if not os.path.exists('outputs'):
        print("âŒ outputs í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤. app.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        exit(1)
    
    # HTML íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
    html_files = glob.glob('outputs/*.html')
    if not html_files:
        print("âŒ HTML íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. app.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        exit(1)
    
    try:
        generate_sitemap()
        generate_rss()
        generate_robots_txt()
        print("ğŸ‰ ëª¨ë“  SEO íŒŒì¼ ìƒì„± ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        exit(1)